---
title: 'Google Capstone Project: How Can Bellabeat ,A Wellness Technology Company
  Play  It Smart'
author: "Sandeep Singh"
date: "3/5/2022"
output:
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Steps-1 : Ask
 We define the issue, the goals of our case study, and the intended result in this step.

#### 1.0 Background
Since 2013, Bellabeat has been a high-tech manufacturer of gorgeously crafted smart devices for women with a focus on their health. Bellabeat has quickly expanded and established itself as a tech-driven wellness brand for women by educating and empowering women with knowledge about their own health and habits.

Urka Sren, co-founder and chief creative officer, is sure that examination of non-Bellebeat customer data, such as usage data from FitBit fitness trackers, will find further development prospects.

#### 1.2 Business Task:
Examine FitBit fitness tracker data to learn how users interact with the FitBit app and identify trends for Bellabeat marketing strategy.

#### 1.3 Business Objectives:

 * What patterns have been found?
 * How might Bellabeat customers be affected by these trends?
 * How can these developments affect Bellabeat's marketing plan?
 
#### 1.4 Deliverables
 * A concise description of the business task
 * A list of all the data sources that were used, along with documentation of any data cleaning or manipulation, and a summary of the analysis
 * supporting images and important findings
 * Recommendations for high-level material based on the analysis
 
#### 1.5 Key Stakeholders
 * Bellabeat's cofounder and chief creative officer, Urka Sren
 * Mathematician, co-founder of Bellabeat, and essential member of the Bellabeat management team, Sando Mur
 * The Bellabeat analytics team for marketing: Data analysts overseeing Bellabeat's marketing plan.
 
### Steps-2 : Prepare
We identify the data being used and its constraints during the Prepare step.

#### Step 2.1 Information on Data Source:
 * 18 csv files containing data from the FitBit fitness tracker are freely accessible on Kaggle.
 * generated by survey participants using Amazon Mechanical Turk between March 12 and May 12, 2016.
 * 30 FitBit users gave their permission for personal tracker data to be submitted.
 * The information gathered includes minute-by-minute records of physical activity, heart rate, sleep patterns, daily activities, and steps.
 
#### 2.2 Limitation of Data Set
 * Data was gathered in 2016 five years ago. Since then, users' routines for everyday activity, eating, exercising, and sleeping may have changed. Data might    not be current or pertinent.
 * A sample size of 30 FitBit users does not accurately represent the fitness market as a whole.
 * We are unable to verify the integrity or correctness of the data because it is acquired through a survey.
 
#### 2.3 Is Data ROCCC?

A good data source is ROCCC which stands for Reliable, Original, Comprehensive, Current, and Cited.

 *  Reliable — LOW — Not reliable as it only has 30 respondents
 *  Original — LOW — Third party provider (Amazon Mechanical Turk)
 *  Comprehensive — MED — Parameters match most of Bellabeat products’ parameters
 *  Current — LOW — Data is 5 years old and may not be relevant
 *  Cited — LOW — Data collected from third party, hence unknown

Overall, the dataset is regarded as having low quality data, and it is not advised to base business suggestions on it.

#### 2.4 Data Selection
The next file is chosen and copied for examination.


#### 2.5 Tool
We are using R for data Cleaning ,transformation and Visualization

'dailyActivity_merged.csv'

### Step-3 Process
Here, we will process the data by cleaning it and making sure it is accurate, pertinent, comprehensive, free of error, and free of outliers by carrying out the following actions:

 * Examine and watch the data
 * Examine and deal with any missing or null values.
 * Data transformation: format the data type
 * Carrying out a preliminary statistical analysis


```{r warning=FALSE}
install.packages("Rtools", repos = "http://cran.us.r-project.org")
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
install.packages("plotrix", repos = "http://cran.us.r-project.org")
install.packages("treemap", repos = "http://cran.us.r-project.org")

```

#### 3.1 Preparing the Enviroment
The R libraries are installed. 
```{r warning=TRUE, include=FALSE}

library('tidyverse')
library('skimr')
library('janitor')
library('dplyr')
library('lubridate')
library('ggplot2')
library('treemap')
#library('reticulate')
```
#### Importing data set 
```{r Importing Data}
dataset<- read.csv("dailyActivity_merged.csv",header=TRUE,sep = ",")
```
#### 3.3 Cleaning and modifying data
 1 Observe and get acquainted with the data
 2 Verify any missing or empty values.
 3 Run a sanity check on the data.
##### Previewing using glimpse function on  daily_activity to familiarise with the data
```{r}
str(dataset)
```
#### Cleaning Column Names
```{r}
dataset<-clean_names(dataset)
colnames(dataset)

```
#### Finding Out Basic Information of Data
No. of Rows and Columns
 * Columns Names
 * Non Null Count
 * Data Type

#### Finding Data Type of Each Column

```{r Data Type of Each Column}
str(dataset)
```

####Finding Unique ID 
```{r}
dataset %>% 
  distinct(id)
```
#### Finding Null and Missing Values
```{r}
sum(is.na(dataset))
```
#### From the Above observation , we noted that
 1. There Zero Null or Missing Values 
 2. Data has 15 Columns 940 Rows
 3. ActivityData is wrongly classified as Object dtype  and has to be converted into datatime64 dtype
 4. Instead of the predicted 30 unique IDs, there are 33 unique IDs. It's possible that some users made more IDs while the survey was being conducted.

Once the corrupt data has been located, we will manipulate or change the data.

 1.Activity Date should be changed to datatime64 dtype.
 2.Change Activity Date's format to yyyy-mm-dd.
 3.For additional research, create a new column called DayOfTheWeek by producing dates as days of the week.
 4.Adding the total of the VeryActiveMinutes, FairlyActiveMinutes, LightlyActiveMinutes, and SedentaryMinutes columns will give you TotalMins.

By changing the new column TotalMins in number 4 to the number of hours, create a new column called TotalHours.
Rename and rearrange the columns.

Prior to converting ActivityDate to yyyy-mm-dd, we will first convert ActivityDate from an object to a datatime64 dtype.
Then we check to see whether ActivityDate has changed to yyyy-mm-dd and Datatime64 Dtype.

#### Converting *Activity Date*  to datetime64 and format to YYYY-MM-DD 
```{r}
View(dataset)
```
 
```{r}

dataset$activity_date <- as.Date(dataset$activity_date, format = "%m/%d/%Y")


```
### Printing First Ten Rows of Dataset to check the changes
```{r}
head(dataset)
```

#### Creating new list 
```{r}
activity_Day <- wday(dataset$activity_date, label=TRUE)
dataset['activity_Day']<-activity_Day
totactive_Minutes<-(dataset$very_active_minutes + dataset$fairly_active_minutes +dataset$lightly_active_minutes +dataset$sedentary_minutes)
dataset['totactive_Minutes']<-totactive_Minutes
totactive_Hours<-ceiling((totactive_Minutes/60))
dataset['totactive_Hours']<-totactive_Hours
View(dataset)

#mutate(dataset, activity_Hours= (dataset$totactive_Minutes/60))
```

#### Step-4 : Analyse
 4.1 Perform calculation

Pulling Calculation
1. Count - No. of Rows
2. Mean  - Average
3. Standard Deviation
4. Min and Max
5.Percentiles 25%, 50%, 75%

```{r}
summary(dataset)
```
Interpreting statistical findings:

1. 
2.
3.

#### STEP 5: Share 

Number of Times users logged in App Across the Week

```{r}
p<-ggplot(data=dataset)

p + geom_bar(mapping = aes(x=activity_Day ))+coord_flip() +theme_classic()+
  labs(title="Number of times users logged in app across the week", x = "Activity Day",y="Frequency")


```

```{r}

p + geom_point(mapping = aes(x= total_steps,y=calories)) +
  geom_smooth(mapping=aes(x=total_steps,y=calories))
  labs(title="Calories burned for every step taken", x = "Steps taken",y="Calories burned") 
  

```
```{r}
p + geom_point(mapping = aes(x = totactive_Hours,y=calories)) +
  labs(title="Calories burned for every hours logged", x = "Total Hours Logged ", y="Calories burned")
```


```{r}
value<-c(sum(dataset$lightly_active_minutes) , sum(dataset$fairly_active_minutes), sum(dataset$very_active_minutes), sum(dataset$sedentary_minutes))
group <- c(" Light active minutes" ,"Fairly active minutes" , "Very active minutes" , "Sedentary minutes")
activity_data <- data.frame(group,value) 
treemap( activity_data,
        index="group",
        vSize = "value",
        type = "index",
        title="Percentage of Activity"
        )

```












